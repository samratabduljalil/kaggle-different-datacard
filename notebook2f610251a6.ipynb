{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3174116,"sourceType":"datasetVersion","datasetId":1929044}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### This notebook was inspired from [medium](https://medium.com/)###and [here](https://www.kaggle.com/code/ammarnassanalhajali/layout-parser-model-training) ##and [here](https://www.kaggle.com/code/salmankhondker/starter-notebook-dl-sprint-2-0)##and [here](https://www.kaggle.com/code/ataullhasaim/mws-dl-enigma-1-0-starter-notebook)","metadata":{}},{"cell_type":"markdown","source":"This is only training code using detectron2","metadata":{}},{"cell_type":"code","source":"!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detectron2 imports\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\nfrom detectron2 import model_zoo\nimport cv2\nimport os\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.structures import BoxMode\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset, LVISEvaluator\nfrom detectron2.data import build_detection_test_loader\nfrom detectron2.utils.visualizer import ColorMode\n\n# other libs (other necessary imports in Colab file to make the list shorter here)\n\nimport torch, torchvision\nfrom pathlib import Path\nimport torchvision.transforms as transforms","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#coco Data create and register\ndef create_data_pairs(input_path, detectron_img_path, detectron_annot_path, dir_type = 'train'):\n\n    img_paths = Path(input_path +'/train/images/').glob('*.jpg')\n\n    pairs = []\n    for img_path in img_paths:\n\n        file_name_tmp = str(img_path).split('/')[-1].split('.')\n        file_name_tmp.pop(-1)\n        file_name = '.'.join((file_name_tmp))\n\n        label_path = Path(input_path + '/train/labels/' + file_name + '.txt')\n\n        if label_path.is_file():\n\n            line_img = detectron_img_path + '/train/images/'+ file_name + '.jpg'\n            line_annot = detectron_annot_path+'/train/labels/' + file_name + '.txt'\n            pairs.append([line_img, line_annot])\n\n    return pairs\n\ninput_path = '/kaggle/input/aquarium-data-cots/aquarium_pretrain'\n\ndetectron_img_path = '/kaggle/input/aquarium-data-cots/aquarium_pretrain'\ndetectron_annot_path = '/kaggle/input/aquarium-data-cots/aquarium_pretrain'\n\ntrain = create_data_pairs(input_path, detectron_img_path, detectron_annot_path, 'train')\nval = create_data_pairs(input_path, detectron_img_path, detectron_annot_path, 'valid')","metadata":{"execution":{"iopub.status.busy":"2024-04-04T19:21:43.884940Z","iopub.execute_input":"2024-04-04T19:21:43.885311Z","iopub.status.idle":"2024-04-04T19:21:43.900212Z","shell.execute_reply.started":"2024-04-04T19:21:43.885283Z","shell.execute_reply":"2024-04-04T19:21:43.899215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2024-04-04T19:21:54.138138Z","iopub.execute_input":"2024-04-04T19:21:54.138495Z","iopub.status.idle":"2024-04-04T19:21:54.144900Z","shell.execute_reply.started":"2024-04-04T19:21:54.138466Z","shell.execute_reply":"2024-04-04T19:21:54.143846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_coco_format(data_pairs):\n    \n    data_list = []\n\n    for i, path in enumerate(data_pairs):\n        \n        filename = path[0]\n\n        img_h, img_w = cv2.imread(filename).shape[:2]\n\n        img_item = {}\n        img_item['file_name'] = filename\n        img_item['image_id'] = i\n        img_item['height']= img_h\n        img_item['width']= img_w\n\n        #print(str(i), filename)\n\n\n        annotations = []\n        with open(path[1]) as annot_file:\n            lines = annot_file.readlines()\n            for line in lines:\n                if line[-1]==\"\\n\":\n                  box = line[:-1].split(' ')\n                else:\n                  box = line.split(' ')\n\n                class_id = box[0]\n                x_c = float(box[1])\n                y_c = float(box[2])\n                width = float(box[3])\n                height = float(box[4])\n\n                x1 = (x_c - (width/2)) * img_w\n                y1 = (y_c - (height/2)) * img_h\n                x2 = (x_c + (width/2)) * img_w\n                y2 = (y_c + (height/2)) * img_h\n\n                annotation = {\n                    \"bbox\": list(map(float,[x1, y1, x2, y2])),\n                    \"bbox_mode\": BoxMode.XYXY_ABS,\n                    \"category_id\": int(class_id),\n                    \"iscrowd\": 0\n                }\n                annotations.append(annotation)\n            img_item[\"annotations\"] = annotations\n        data_list.append(img_item)\n    return data_list \n\ntrain_list = create_coco_format(train)\nval_list = create_coco_format(val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for catalog_name, file_annots in [(\"train\", train_list), (\"val\", val_list)]:\n    DatasetCatalog.register(catalog_name, lambda file_annots = file_annots: file_annots)\n    MetadataCatalog.get(catalog_name).set(thing_classes=['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray'])\n\nmetadata = MetadataCatalog.get(\"train\") ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training \n#increase max iter accordingly.\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"train\",)\ncfg.DATALOADER.NUM_WORKERS = 2\ncfg.MODEL.DEVICE = 'cuda' # cuda\ncfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\ncfg.SOLVER.IMS_PER_BATCH = 2\ncfg.SOLVER.CHECKPOINT_PERIOD = 500\ncfg.SOLVER.WARMUP_ITERS = 500\ncfg.SOLVER.GAMMA = 0.0005\ncfg.SOLVER.BASE_LR = 0.005\ncfg.SOLVER.MAX_ITER = 2000 # (train_size / batch_size) * 100\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 # 512\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(\"train\").thing_classes)\ncfg.SOLVER.STEPS = (20500, )\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = DefaultTrainer(cfg)\ntrainer.resume_or_load(resume=False)\n\nimport time as t\ns1 = t.time()\ntry:\n  trainer.train()\nexcept:\n  None\ns2 = t.time()\nprint(s2-s1)","metadata":{},"execution_count":null,"outputs":[]}]}