{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "253b0fa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T20:07:29.433918Z",
     "iopub.status.busy": "2024-04-04T20:07:29.433556Z",
     "iopub.status.idle": "2024-04-04T20:09:36.356186Z",
     "shell.execute_reply": "2024-04-04T20:09:36.355223Z"
    },
    "papermill": {
     "duration": 126.929528,
     "end_time": "2024-04-04T20:09:36.358606",
     "exception": false,
     "start_time": "2024-04-04T20:07:29.429078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/detectron2.git\r\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-xdw3ft79\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-xdw3ft79\r\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit b7c7f4ba82192ff06f2bbb162b9f67b00ea55867\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (9.5.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (3.7.5)\r\n",
      "Collecting pycocotools>=2.0.2 (from detectron2==0.6)\r\n",
      "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\r\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.4.0)\r\n",
      "Collecting yacs>=0.1.8 (from detectron2==0.6)\r\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\r\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (0.9.0)\r\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.2.1)\r\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (4.66.1)\r\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (2.15.1)\r\n",
      "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\r\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\r\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\r\n",
      "Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\r\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting hydra-core>=1.1 (from detectron2==0.6)\r\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\r\n",
      "Collecting black (from detectron2==0.6)\r\n",
      "  Downloading black-24.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (75 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from detectron2==0.6) (21.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.1)\r\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\r\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\r\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (1.4.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (8.1.7)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (1.0.0)\r\n",
      "Collecting packaging (from detectron2==0.6)\r\n",
      "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\r\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (4.2.0)\r\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (2.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black->detectron2==0.6) (4.9.0)\r\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.4.0)\r\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.51.1)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.26.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.2.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.5.2)\r\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (2.31.0)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (69.0.3)\r\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (1.16.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->detectron2==0.6) (3.0.1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.3)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.5.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\r\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\r\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\r\n",
      "Downloading black-24.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\r\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\r\n",
      "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\r\n",
      "  Building wheel for detectron2 (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for detectron2: filename=detectron2-0.6-cp310-cp310-linux_x86_64.whl size=1261333 sha256=20d5e1913673363751c9273049797891ecd9e28cc6049b4d03ed6d821d1978e4\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ua2l1ddb/wheels/47/e5/15/94c80df2ba85500c5d76599cc307c0a7079d0e221bb6fc4375\r\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=2e89739beb32e25445c6063eef00b104a82c0925e49618cc2d258755474b4817\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=81dbef88abd45321e44ac01207d0ac0aa7ba7bb56488f122f5b97f008dfcb038\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\r\n",
      "Successfully built detectron2 fvcore antlr4-python3-runtime\r\n",
      "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, packaging, omegaconf, iopath, hydra-core, black, pycocotools, fvcore, detectron2\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 21.3\r\n",
      "    Uninstalling packaging-21.3:\r\n",
      "      Successfully uninstalled packaging-21.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "keras-cv 0.8.2 requires keras-core, which is not installed.\r\n",
      "keras-nlp 0.8.2 requires keras-core, which is not installed.\r\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\r\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\r\n",
      "dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.0 which is incompatible.\r\n",
      "jupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 black-24.3.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 omegaconf-2.3.0 packaging-24.0 pathspec-0.12.1 portalocker-2.8.2 pycocotools-2.0.7 yacs-0.1.8\r\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d91b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T20:09:36.377276Z",
     "iopub.status.busy": "2024-04-04T20:09:36.376511Z",
     "iopub.status.idle": "2024-04-04T20:09:41.702216Z",
     "shell.execute_reply": "2024-04-04T20:09:41.701403Z"
    },
    "papermill": {
     "duration": 5.337454,
     "end_time": "2024-04-04T20:09:41.704679",
     "exception": false,
     "start_time": "2024-04-04T20:09:36.367225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# detectron2 imports\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2 import model_zoo\n",
    "import cv2\n",
    "import os\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset, LVISEvaluator\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# other libs (other necessary imports in Colab file to make the list shorter here)\n",
    "\n",
    "import torch, torchvision\n",
    "from pathlib import Path\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c77280",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T20:09:41.724206Z",
     "iopub.status.busy": "2024-04-04T20:09:41.723129Z",
     "iopub.status.idle": "2024-04-04T20:10:11.558985Z",
     "shell.execute_reply": "2024-04-04T20:10:11.558153Z"
    },
    "papermill": {
     "duration": 29.848183,
     "end_time": "2024-04-04T20:10:11.561402",
     "exception": false,
     "start_time": "2024-04-04T20:09:41.713219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#coco Data create and register\n",
    "def create_data_pairs(input_path, detectron_img_path, detectron_annot_path, dir_type = 'train'):\n",
    "\n",
    "    img_paths = Path(input_path +'/train/images/').glob('*.jpg')\n",
    "\n",
    "    pairs = []\n",
    "    for img_path in img_paths:\n",
    "\n",
    "        file_name_tmp = str(img_path).split('/')[-1].split('.')\n",
    "        file_name_tmp.pop(-1)\n",
    "        file_name = '.'.join((file_name_tmp))\n",
    "\n",
    "        label_path = Path(input_path + '/train/labels/' + file_name + '.txt')\n",
    "\n",
    "        if label_path.is_file():\n",
    "\n",
    "            line_img = detectron_img_path + '/train/images/'+ file_name + '.jpg'\n",
    "            line_annot = detectron_annot_path+'/train/labels/' + file_name + '.txt'\n",
    "            pairs.append([line_img, line_annot])\n",
    "\n",
    "    return pairs\n",
    "\n",
    "input_path = '/kaggle/input/cardetection'\n",
    "\n",
    "detectron_img_path = '/kaggle/input/cardetection'\n",
    "detectron_annot_path = '/kaggle/input/cardetection'\n",
    "\n",
    "train = create_data_pairs(input_path, detectron_img_path, detectron_annot_path, 'train')\n",
    "val = create_data_pairs(input_path, detectron_img_path, detectron_annot_path, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8a4b05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T20:10:11.579971Z",
     "iopub.status.busy": "2024-04-04T20:10:11.579241Z",
     "iopub.status.idle": "2024-04-04T20:11:28.660839Z",
     "shell.execute_reply": "2024-04-04T20:11:28.659775Z"
    },
    "papermill": {
     "duration": 77.093345,
     "end_time": "2024-04-04T20:11:28.663249",
     "exception": false,
     "start_time": "2024-04-04T20:10:11.569904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_coco_format(data_pairs):\n",
    "    \n",
    "    data_list = []\n",
    "\n",
    "    for i, path in enumerate(data_pairs):\n",
    "        \n",
    "        filename = path[0]\n",
    "\n",
    "        img_h, img_w = cv2.imread(filename).shape[:2]\n",
    "\n",
    "        img_item = {}\n",
    "        img_item['file_name'] = filename\n",
    "        img_item['image_id'] = i\n",
    "        img_item['height']= img_h\n",
    "        img_item['width']= img_w\n",
    "\n",
    "        #print(str(i), filename)\n",
    "\n",
    "\n",
    "        annotations = []\n",
    "        with open(path[1]) as annot_file:\n",
    "            lines = annot_file.readlines()\n",
    "            for line in lines:\n",
    "                if line[-1]==\"\\n\":\n",
    "                  box = line[:-1].split(' ')\n",
    "                else:\n",
    "                  box = line.split(' ')\n",
    "\n",
    "                class_id = box[0]\n",
    "                x_c = float(box[1])\n",
    "                y_c = float(box[2])\n",
    "                width = float(box[3])\n",
    "                height = float(box[4])\n",
    "\n",
    "                x1 = (x_c - (width/2)) * img_w\n",
    "                y1 = (y_c - (height/2)) * img_h\n",
    "                x2 = (x_c + (width/2)) * img_w\n",
    "                y2 = (y_c + (height/2)) * img_h\n",
    "\n",
    "                annotation = {\n",
    "                    \"bbox\": list(map(float,[x1, y1, x2, y2])),\n",
    "                    \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "                    \"category_id\": int(class_id),\n",
    "                    \"iscrowd\": 0\n",
    "                }\n",
    "                annotations.append(annotation)\n",
    "            img_item[\"annotations\"] = annotations\n",
    "        data_list.append(img_item)\n",
    "    return data_list \n",
    "\n",
    "train_list = create_coco_format(train)\n",
    "val_list = create_coco_format(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d81c0d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T20:11:28.681880Z",
     "iopub.status.busy": "2024-04-04T20:11:28.681025Z",
     "iopub.status.idle": "2024-04-04T20:11:28.687016Z",
     "shell.execute_reply": "2024-04-04T20:11:28.686130Z"
    },
    "papermill": {
     "duration": 0.017303,
     "end_time": "2024-04-04T20:11:28.689054",
     "exception": false,
     "start_time": "2024-04-04T20:11:28.671751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for catalog_name, file_annots in [(\"train\", train_list), (\"val\", val_list)]:\n",
    "    DatasetCatalog.register(catalog_name, lambda file_annots = file_annots: file_annots)\n",
    "    MetadataCatalog.get(catalog_name).set(thing_classes=['Green Light', 'Red Light', 'Speed Limit 10', 'Speed Limit 100', 'Speed Limit 110', 'Speed Limit 120', 'Speed Limit 20', 'Speed Limit 30', 'Speed Limit 40', 'Speed Limit 50', 'Speed Limit 60', 'Speed Limit 70', 'Speed Limit 80', 'Speed Limit 90', 'Stop'])\n",
    "\n",
    "metadata = MetadataCatalog.get(\"train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebb6c88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T20:11:28.707574Z",
     "iopub.status.busy": "2024-04-04T20:11:28.707220Z",
     "iopub.status.idle": "2024-04-04T20:11:28.715095Z",
     "shell.execute_reply": "2024-04-04T20:11:28.714156Z"
    },
    "papermill": {
     "duration": 0.019462,
     "end_time": "2024-04-04T20:11:28.717078",
     "exception": false,
     "start_time": "2024-04-04T20:11:28.697616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom augmentation function\n",
    "def custom_mapper(dataset_dict):\n",
    "     dataset_dict = copy.deepcopy(dataset_dict)\n",
    "     image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "\n",
    "     transform_list = [T.RandomBrightness(0.5, 1.2),\n",
    "                      T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "                      T.RandomFlip(prob=0.5, horizontal=True, vertical=False)\n",
    "                      ]\n",
    "     image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "\n",
    "     dataset_dict[\"image\"] = torch.as_tensor(\n",
    "        image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "     annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "     ]\n",
    "     instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "\n",
    "     dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "     return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c9db87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-04T20:11:28.734911Z",
     "iopub.status.busy": "2024-04-04T20:11:28.734533Z",
     "iopub.status.idle": "2024-04-04T20:18:05.377085Z",
     "shell.execute_reply": "2024-04-04T20:18:05.376047Z"
    },
    "papermill": {
     "duration": 396.653929,
     "end_time": "2024-04-04T20:18:05.379198",
     "exception": false,
     "start_time": "2024-04-04T20:11:28.725269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/04 20:11:29 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=16, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=60, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[04/04 20:11:29 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 3527 images left.\n",
      "\u001b[32m[04/04 20:11:29 d2.data.build]: \u001b[0mDistribution of instances among all 15 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|  Green Light  | 542          |   Red Light   | 585          | Speed Limit.. | 19           |\n",
      "| Speed Limit.. | 267          | Speed Limit.. | 101          | Speed Limit.. | 252          |\n",
      "| Speed Limit.. | 285          | Speed Limit.. | 334          | Speed Limit.. | 235          |\n",
      "| Speed Limit.. | 283          | Speed Limit.. | 301          | Speed Limit.. | 318          |\n",
      "| Speed Limit.. | 323          | Speed Limit.. | 168          |     Stop      | 285          |\n",
      "|               |              |               |              |               |              |\n",
      "|     total     | 4298         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[04/04 20:11:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[04/04 20:11:29 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/04 20:11:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/04 20:11:29 d2.data.common]: \u001b[0mSerializing 3527 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/04 20:11:30 d2.data.common]: \u001b[0mSerialized dataset takes 1.12 MiB\n",
      "\u001b[32m[04/04 20:11:30 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/04 20:11:30 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[04/04 20:11:30 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_280758.pkl: 167MB [00:00, 200MB/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/04 20:11:31 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/04 20:11:38 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 19  total_loss: 2.496  loss_cls: 2.393  loss_box_reg: 0.2335  loss_rpn_cls: 0.007638  loss_rpn_loc: 0.01157    time: 0.1994  last_time: 0.2060  data_time: 0.0110  last_data_time: 0.0047   lr: 0.00019481  max_mem: 1742M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-04 20:11:40.418489: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-04 20:11:40.418598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-04 20:11:40.553471: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/04 20:11:54 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 39  total_loss: 0.5992  loss_cls: 0.3456  loss_box_reg: 0.2382  loss_rpn_cls: 0.00351  loss_rpn_loc: 0.006771    time: 0.1980  last_time: 0.1755  data_time: 0.0057  last_data_time: 0.0054   lr: 0.00039461  max_mem: 1743M\n",
      "\u001b[32m[04/04 20:11:58 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 59  total_loss: 0.574  loss_cls: 0.2937  loss_box_reg: 0.2714  loss_rpn_cls: 0.005379  loss_rpn_loc: 0.005061    time: 0.1956  last_time: 0.2094  data_time: 0.0056  last_data_time: 0.0055   lr: 0.00059441  max_mem: 1743M\n",
      "\u001b[32m[04/04 20:12:01 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 79  total_loss: 0.5398  loss_cls: 0.271  loss_box_reg: 0.2284  loss_rpn_cls: 0.008887  loss_rpn_loc: 0.004951    time: 0.1935  last_time: 0.2019  data_time: 0.0053  last_data_time: 0.0059   lr: 0.00079421  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:05 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 99  total_loss: 0.5931  loss_cls: 0.2799  loss_box_reg: 0.3032  loss_rpn_cls: 0.002422  loss_rpn_loc: 0.0033    time: 0.1921  last_time: 0.1842  data_time: 0.0054  last_data_time: 0.0055   lr: 0.00099401  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:09 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 119  total_loss: 0.5883  loss_cls: 0.2747  loss_box_reg: 0.2868  loss_rpn_cls: 0.001745  loss_rpn_loc: 0.003017    time: 0.1926  last_time: 0.1914  data_time: 0.0058  last_data_time: 0.0067   lr: 0.0011938  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:13 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 139  total_loss: 0.4975  loss_cls: 0.2413  loss_box_reg: 0.2509  loss_rpn_cls: 0.001514  loss_rpn_loc: 0.003605    time: 0.1923  last_time: 0.2006  data_time: 0.0056  last_data_time: 0.0059   lr: 0.0013936  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:17 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 159  total_loss: 0.4883  loss_cls: 0.2311  loss_box_reg: 0.2268  loss_rpn_cls: 0.004431  loss_rpn_loc: 0.005467    time: 0.1917  last_time: 0.1880  data_time: 0.0057  last_data_time: 0.0065   lr: 0.0015934  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:20 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 179  total_loss: 0.5375  loss_cls: 0.2479  loss_box_reg: 0.2674  loss_rpn_cls: 0.005723  loss_rpn_loc: 0.003324    time: 0.1909  last_time: 0.1713  data_time: 0.0055  last_data_time: 0.0056   lr: 0.0017932  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:24 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 199  total_loss: 0.5577  loss_cls: 0.2595  loss_box_reg: 0.2619  loss_rpn_cls: 0.001078  loss_rpn_loc: 0.003207    time: 0.1907  last_time: 0.1894  data_time: 0.0061  last_data_time: 0.0053   lr: 0.001993  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:28 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 219  total_loss: 0.5989  loss_cls: 0.284  loss_box_reg: 0.2252  loss_rpn_cls: 0.002485  loss_rpn_loc: 0.0051    time: 0.1910  last_time: 0.1602  data_time: 0.0059  last_data_time: 0.0058   lr: 0.0021928  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:32 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 239  total_loss: 0.4779  loss_cls: 0.2653  loss_box_reg: 0.1898  loss_rpn_cls: 0.0009326  loss_rpn_loc: 0.00482    time: 0.1905  last_time: 0.1863  data_time: 0.0052  last_data_time: 0.0056   lr: 0.0023926  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:35 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 259  total_loss: 0.4751  loss_cls: 0.2979  loss_box_reg: 0.1734  loss_rpn_cls: 0.00107  loss_rpn_loc: 0.003989    time: 0.1900  last_time: 0.1588  data_time: 0.0055  last_data_time: 0.0056   lr: 0.0025924  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:39 d2.utils.events]: \u001b[0m eta: 0:05:24  iter: 279  total_loss: 0.4003  loss_cls: 0.2278  loss_box_reg: 0.165  loss_rpn_cls: 0.006859  loss_rpn_loc: 0.004985    time: 0.1897  last_time: 0.2017  data_time: 0.0064  last_data_time: 0.0048   lr: 0.0027922  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:43 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 299  total_loss: 0.4388  loss_cls: 0.2314  loss_box_reg: 0.139  loss_rpn_cls: 0.0003653  loss_rpn_loc: 0.005171    time: 0.1897  last_time: 0.2014  data_time: 0.0050  last_data_time: 0.0051   lr: 0.002992  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:47 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 319  total_loss: 0.3568  loss_cls: 0.2339  loss_box_reg: 0.1117  loss_rpn_cls: 0.002524  loss_rpn_loc: 0.004179    time: 0.1891  last_time: 0.1570  data_time: 0.0052  last_data_time: 0.0056   lr: 0.0031918  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:50 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 339  total_loss: 0.391  loss_cls: 0.2442  loss_box_reg: 0.1172  loss_rpn_cls: 0.001735  loss_rpn_loc: 0.004461    time: 0.1888  last_time: 0.2008  data_time: 0.0053  last_data_time: 0.0059   lr: 0.0033916  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:54 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 359  total_loss: 0.3382  loss_cls: 0.2223  loss_box_reg: 0.108  loss_rpn_cls: 0.001987  loss_rpn_loc: 0.005585    time: 0.1886  last_time: 0.2031  data_time: 0.0057  last_data_time: 0.0052   lr: 0.0035914  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:12:58 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 379  total_loss: 0.3049  loss_cls: 0.2016  loss_box_reg: 0.08197  loss_rpn_cls: 0.002071  loss_rpn_loc: 0.005828    time: 0.1883  last_time: 0.1690  data_time: 0.0052  last_data_time: 0.0047   lr: 0.0037912  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:01 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 399  total_loss: 0.3746  loss_cls: 0.2207  loss_box_reg: 0.1016  loss_rpn_cls: 0.002622  loss_rpn_loc: 0.004491    time: 0.1881  last_time: 0.1872  data_time: 0.0051  last_data_time: 0.0050   lr: 0.003991  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:05 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 419  total_loss: 0.3297  loss_cls: 0.2221  loss_box_reg: 0.105  loss_rpn_cls: 0.004699  loss_rpn_loc: 0.007368    time: 0.1879  last_time: 0.1806  data_time: 0.0052  last_data_time: 0.0056   lr: 0.0041908  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:09 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 439  total_loss: 0.3496  loss_cls: 0.1895  loss_box_reg: 0.1145  loss_rpn_cls: 0.001076  loss_rpn_loc: 0.005389    time: 0.1877  last_time: 0.1867  data_time: 0.0058  last_data_time: 0.0059   lr: 0.0043906  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:12 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 459  total_loss: 0.2902  loss_cls: 0.1728  loss_box_reg: 0.08391  loss_rpn_cls: 0.001193  loss_rpn_loc: 0.003775    time: 0.1874  last_time: 0.1705  data_time: 0.0059  last_data_time: 0.0049   lr: 0.0045904  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:16 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 479  total_loss: 0.3443  loss_cls: 0.2345  loss_box_reg: 0.114  loss_rpn_cls: 0.0002517  loss_rpn_loc: 0.003235    time: 0.1876  last_time: 0.1614  data_time: 0.0060  last_data_time: 0.0049   lr: 0.0047902  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:20 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 499  total_loss: 0.2692  loss_cls: 0.1158  loss_box_reg: 0.1008  loss_rpn_cls: 0.01329  loss_rpn_loc: 0.006724    time: 0.1873  last_time: 0.1809  data_time: 0.0053  last_data_time: 0.0059   lr: 0.00499  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:24 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 519  total_loss: 0.3693  loss_cls: 0.2165  loss_box_reg: 0.1156  loss_rpn_cls: 0.002066  loss_rpn_loc: 0.004073    time: 0.1871  last_time: 0.1671  data_time: 0.0060  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:28 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 539  total_loss: 0.3134  loss_cls: 0.1725  loss_box_reg: 0.09263  loss_rpn_cls: 0.008323  loss_rpn_loc: 0.005372    time: 0.1868  last_time: 0.1841  data_time: 0.0055  last_data_time: 0.0055   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:33 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 559  total_loss: 0.3061  loss_cls: 0.1893  loss_box_reg: 0.08661  loss_rpn_cls: 0.006282  loss_rpn_loc: 0.003416    time: 0.1867  last_time: 0.1666  data_time: 0.0055  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:36 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 579  total_loss: 0.2819  loss_cls: 0.1728  loss_box_reg: 0.08178  loss_rpn_cls: 0.003941  loss_rpn_loc: 0.003348    time: 0.1863  last_time: 0.1851  data_time: 0.0053  last_data_time: 0.0047   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:40 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 599  total_loss: 0.2837  loss_cls: 0.1793  loss_box_reg: 0.07857  loss_rpn_cls: 0.00256  loss_rpn_loc: 0.00392    time: 0.1863  last_time: 0.1656  data_time: 0.0050  last_data_time: 0.0051   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:43 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 619  total_loss: 0.3409  loss_cls: 0.2089  loss_box_reg: 0.09383  loss_rpn_cls: 0.0009689  loss_rpn_loc: 0.00365    time: 0.1860  last_time: 0.1645  data_time: 0.0059  last_data_time: 0.0055   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:47 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 639  total_loss: 0.3595  loss_cls: 0.2431  loss_box_reg: 0.1073  loss_rpn_cls: 0.0009971  loss_rpn_loc: 0.003584    time: 0.1861  last_time: 0.1858  data_time: 0.0053  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:51 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 659  total_loss: 0.3202  loss_cls: 0.209  loss_box_reg: 0.09902  loss_rpn_cls: 0.001018  loss_rpn_loc: 0.003582    time: 0.1861  last_time: 0.2042  data_time: 0.0054  last_data_time: 0.0062   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:55 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 679  total_loss: 0.2917  loss_cls: 0.1831  loss_box_reg: 0.06972  loss_rpn_cls: 0.000824  loss_rpn_loc: 0.002512    time: 0.1860  last_time: 0.1670  data_time: 0.0051  last_data_time: 0.0047   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:13:58 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 699  total_loss: 0.3063  loss_cls: 0.1747  loss_box_reg: 0.1105  loss_rpn_cls: 0.004119  loss_rpn_loc: 0.00533    time: 0.1859  last_time: 0.1777  data_time: 0.0051  last_data_time: 0.0051   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:02 d2.utils.events]: \u001b[0m eta: 0:03:58  iter: 719  total_loss: 0.3189  loss_cls: 0.1785  loss_box_reg: 0.09858  loss_rpn_cls: 0.0008994  loss_rpn_loc: 0.003687    time: 0.1858  last_time: 0.1813  data_time: 0.0051  last_data_time: 0.0052   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:05 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 739  total_loss: 0.2755  loss_cls: 0.1652  loss_box_reg: 0.07665  loss_rpn_cls: 0.001108  loss_rpn_loc: 0.003343    time: 0.1855  last_time: 0.1734  data_time: 0.0053  last_data_time: 0.0054   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:09 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 759  total_loss: 0.3015  loss_cls: 0.1919  loss_box_reg: 0.0843  loss_rpn_cls: 0.001797  loss_rpn_loc: 0.00408    time: 0.1855  last_time: 0.1882  data_time: 0.0052  last_data_time: 0.0055   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:13 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 779  total_loss: 0.3339  loss_cls: 0.1992  loss_box_reg: 0.08678  loss_rpn_cls: 0.001526  loss_rpn_loc: 0.01104    time: 0.1856  last_time: 0.2060  data_time: 0.0058  last_data_time: 0.0063   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:17 d2.utils.events]: \u001b[0m eta: 0:03:43  iter: 799  total_loss: 0.3079  loss_cls: 0.1593  loss_box_reg: 0.1128  loss_rpn_cls: 0.001495  loss_rpn_loc: 0.004875    time: 0.1855  last_time: 0.2024  data_time: 0.0058  last_data_time: 0.0063   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:20 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 819  total_loss: 0.3287  loss_cls: 0.2109  loss_box_reg: 0.1015  loss_rpn_cls: 0.00263  loss_rpn_loc: 0.003175    time: 0.1854  last_time: 0.1772  data_time: 0.0054  last_data_time: 0.0049   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:24 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 839  total_loss: 0.2977  loss_cls: 0.1643  loss_box_reg: 0.08719  loss_rpn_cls: 0.001018  loss_rpn_loc: 0.003582    time: 0.1853  last_time: 0.1942  data_time: 0.0057  last_data_time: 0.0062   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:28 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 859  total_loss: 0.2822  loss_cls: 0.1964  loss_box_reg: 0.06811  loss_rpn_cls: 0.000304  loss_rpn_loc: 0.002063    time: 0.1854  last_time: 0.1829  data_time: 0.0053  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:31 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 879  total_loss: 0.3145  loss_cls: 0.1824  loss_box_reg: 0.1006  loss_rpn_cls: 0.002791  loss_rpn_loc: 0.00707    time: 0.1854  last_time: 0.1841  data_time: 0.0054  last_data_time: 0.0053   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:35 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 899  total_loss: 0.2844  loss_cls: 0.1881  loss_box_reg: 0.06928  loss_rpn_cls: 0.0002668  loss_rpn_loc: 0.001859    time: 0.1855  last_time: 0.1649  data_time: 0.0056  last_data_time: 0.0060   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:39 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 919  total_loss: 0.2412  loss_cls: 0.1519  loss_box_reg: 0.06843  loss_rpn_cls: 0.001494  loss_rpn_loc: 0.003595    time: 0.1854  last_time: 0.2027  data_time: 0.0053  last_data_time: 0.0057   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:42 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 939  total_loss: 0.2664  loss_cls: 0.1535  loss_box_reg: 0.0764  loss_rpn_cls: 0.0006923  loss_rpn_loc: 0.003103    time: 0.1853  last_time: 0.1683  data_time: 0.0051  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:46 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 959  total_loss: 0.2604  loss_cls: 0.1874  loss_box_reg: 0.07252  loss_rpn_cls: 0.001467  loss_rpn_loc: 0.002646    time: 0.1854  last_time: 0.1749  data_time: 0.0059  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:50 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 979  total_loss: 0.3118  loss_cls: 0.186  loss_box_reg: 0.1002  loss_rpn_cls: 0.002018  loss_rpn_loc: 0.005455    time: 0.1854  last_time: 0.1867  data_time: 0.0050  last_data_time: 0.0048   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:54 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 999  total_loss: 0.2995  loss_cls: 0.1696  loss_box_reg: 0.08599  loss_rpn_cls: 0.00167  loss_rpn_loc: 0.004629    time: 0.1852  last_time: 0.1690  data_time: 0.0052  last_data_time: 0.0048   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:14:58 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 1019  total_loss: 0.2518  loss_cls: 0.1675  loss_box_reg: 0.0668  loss_rpn_cls: 0.001584  loss_rpn_loc: 0.003501    time: 0.1853  last_time: 0.2055  data_time: 0.0052  last_data_time: 0.0055   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:02 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 1039  total_loss: 0.2658  loss_cls: 0.1643  loss_box_reg: 0.07512  loss_rpn_cls: 0.0005233  loss_rpn_loc: 0.002379    time: 0.1853  last_time: 0.1485  data_time: 0.0051  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:05 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 1059  total_loss: 0.3043  loss_cls: 0.1898  loss_box_reg: 0.09928  loss_rpn_cls: 0.0009211  loss_rpn_loc: 0.003223    time: 0.1852  last_time: 0.1667  data_time: 0.0055  last_data_time: 0.0052   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:10 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 1079  total_loss: 0.3382  loss_cls: 0.2029  loss_box_reg: 0.09876  loss_rpn_cls: 0.0009086  loss_rpn_loc: 0.003755    time: 0.1851  last_time: 0.1865  data_time: 0.0054  last_data_time: 0.0057   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:14 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 1099  total_loss: 0.2454  loss_cls: 0.1471  loss_box_reg: 0.08587  loss_rpn_cls: 0.0015  loss_rpn_loc: 0.003748    time: 0.1851  last_time: 0.1575  data_time: 0.0056  last_data_time: 0.0055   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:18 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 1119  total_loss: 0.2841  loss_cls: 0.1652  loss_box_reg: 0.08653  loss_rpn_cls: 0.0005397  loss_rpn_loc: 0.004218    time: 0.1852  last_time: 0.1862  data_time: 0.0060  last_data_time: 0.0045   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:21 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 1139  total_loss: 0.2783  loss_cls: 0.1673  loss_box_reg: 0.09682  loss_rpn_cls: 0.0006167  loss_rpn_loc: 0.003836    time: 0.1851  last_time: 0.1633  data_time: 0.0054  last_data_time: 0.0049   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:25 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 1159  total_loss: 0.3076  loss_cls: 0.1606  loss_box_reg: 0.07126  loss_rpn_cls: 0.006218  loss_rpn_loc: 0.003753    time: 0.1851  last_time: 0.1982  data_time: 0.0052  last_data_time: 0.0049   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:29 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 1179  total_loss: 0.2429  loss_cls: 0.1544  loss_box_reg: 0.06493  loss_rpn_cls: 0.003957  loss_rpn_loc: 0.003173    time: 0.1851  last_time: 0.1854  data_time: 0.0054  last_data_time: 0.0053   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:32 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 1199  total_loss: 0.2837  loss_cls: 0.1654  loss_box_reg: 0.1065  loss_rpn_cls: 0.002421  loss_rpn_loc: 0.01003    time: 0.1851  last_time: 0.1844  data_time: 0.0052  last_data_time: 0.0057   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:36 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 1219  total_loss: 0.2787  loss_cls: 0.1928  loss_box_reg: 0.07719  loss_rpn_cls: 0.0005935  loss_rpn_loc: 0.002347    time: 0.1852  last_time: 0.1853  data_time: 0.0056  last_data_time: 0.0053   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:40 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 1239  total_loss: 0.3176  loss_cls: 0.1746  loss_box_reg: 0.07835  loss_rpn_cls: 0.001907  loss_rpn_loc: 0.003293    time: 0.1852  last_time: 0.1865  data_time: 0.0059  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:44 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1259  total_loss: 0.2651  loss_cls: 0.1829  loss_box_reg: 0.06779  loss_rpn_cls: 0.0006027  loss_rpn_loc: 0.002846    time: 0.1852  last_time: 0.1755  data_time: 0.0051  last_data_time: 0.0049   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:48 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 1279  total_loss: 0.3111  loss_cls: 0.1953  loss_box_reg: 0.09755  loss_rpn_cls: 0.003168  loss_rpn_loc: 0.003485    time: 0.1854  last_time: 0.2034  data_time: 0.0055  last_data_time: 0.0054   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:51 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 1299  total_loss: 0.2714  loss_cls: 0.1624  loss_box_reg: 0.08262  loss_rpn_cls: 0.002551  loss_rpn_loc: 0.004121    time: 0.1854  last_time: 0.1807  data_time: 0.0056  last_data_time: 0.0055   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:55 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 1319  total_loss: 0.1956  loss_cls: 0.1214  loss_box_reg: 0.07047  loss_rpn_cls: 0.0005741  loss_rpn_loc: 0.002837    time: 0.1855  last_time: 0.2036  data_time: 0.0055  last_data_time: 0.0051   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:15:59 d2.utils.events]: \u001b[0m eta: 0:02:01  iter: 1339  total_loss: 0.2732  loss_cls: 0.1738  loss_box_reg: 0.07252  loss_rpn_cls: 0.00086  loss_rpn_loc: 0.003088    time: 0.1855  last_time: 0.1823  data_time: 0.0054  last_data_time: 0.0052   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:03 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 1359  total_loss: 0.296  loss_cls: 0.1502  loss_box_reg: 0.07172  loss_rpn_cls: 0.002253  loss_rpn_loc: 0.003024    time: 0.1855  last_time: 0.1834  data_time: 0.0054  last_data_time: 0.0058   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:06 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 1379  total_loss: 0.2391  loss_cls: 0.1406  loss_box_reg: 0.07204  loss_rpn_cls: 0.004168  loss_rpn_loc: 0.0082    time: 0.1855  last_time: 0.1860  data_time: 0.0052  last_data_time: 0.0051   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:10 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 1399  total_loss: 0.215  loss_cls: 0.1477  loss_box_reg: 0.08241  loss_rpn_cls: 0.001042  loss_rpn_loc: 0.004054    time: 0.1855  last_time: 0.1885  data_time: 0.0056  last_data_time: 0.0058   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:14 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 1419  total_loss: 0.2502  loss_cls: 0.1698  loss_box_reg: 0.07796  loss_rpn_cls: 0.001033  loss_rpn_loc: 0.002809    time: 0.1855  last_time: 0.1602  data_time: 0.0057  last_data_time: 0.0049   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:17 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 1439  total_loss: 0.2811  loss_cls: 0.1533  loss_box_reg: 0.07481  loss_rpn_cls: 0.003223  loss_rpn_loc: 0.008052    time: 0.1855  last_time: 0.1775  data_time: 0.0058  last_data_time: 0.0060   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:21 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 1459  total_loss: 0.2584  loss_cls: 0.186  loss_box_reg: 0.06036  loss_rpn_cls: 0.0005205  loss_rpn_loc: 0.002065    time: 0.1854  last_time: 0.1989  data_time: 0.0055  last_data_time: 0.0053   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:25 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 1479  total_loss: 0.2329  loss_cls: 0.1465  loss_box_reg: 0.08417  loss_rpn_cls: 0.0002324  loss_rpn_loc: 0.002937    time: 0.1855  last_time: 0.2072  data_time: 0.0057  last_data_time: 0.0062   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:29 d2.utils.events]: \u001b[0m eta: 0:01:32  iter: 1499  total_loss: 0.2596  loss_cls: 0.1576  loss_box_reg: 0.07504  loss_rpn_cls: 0.0003016  loss_rpn_loc: 0.002059    time: 0.1855  last_time: 0.2024  data_time: 0.0055  last_data_time: 0.0052   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:33 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 1519  total_loss: 0.2336  loss_cls: 0.1494  loss_box_reg: 0.08003  loss_rpn_cls: 0.0009754  loss_rpn_loc: 0.003051    time: 0.1857  last_time: 0.2035  data_time: 0.0055  last_data_time: 0.0058   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:37 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 1539  total_loss: 0.2342  loss_cls: 0.1646  loss_box_reg: 0.05873  loss_rpn_cls: 0.0007014  loss_rpn_loc: 0.003391    time: 0.1857  last_time: 0.1837  data_time: 0.0059  last_data_time: 0.0052   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:42 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 1559  total_loss: 0.2442  loss_cls: 0.1523  loss_box_reg: 0.07433  loss_rpn_cls: 0.001574  loss_rpn_loc: 0.005701    time: 0.1857  last_time: 0.1849  data_time: 0.0051  last_data_time: 0.0049   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:46 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 1579  total_loss: 0.2738  loss_cls: 0.2047  loss_box_reg: 0.07871  loss_rpn_cls: 0.001369  loss_rpn_loc: 0.003681    time: 0.1857  last_time: 0.1622  data_time: 0.0056  last_data_time: 0.0057   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:49 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 1599  total_loss: 0.2775  loss_cls: 0.1704  loss_box_reg: 0.06864  loss_rpn_cls: 0.001101  loss_rpn_loc: 0.003016    time: 0.1857  last_time: 0.1819  data_time: 0.0056  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:53 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 1619  total_loss: 0.2352  loss_cls: 0.1568  loss_box_reg: 0.07412  loss_rpn_cls: 0.0009404  loss_rpn_loc: 0.003066    time: 0.1858  last_time: 0.2143  data_time: 0.0053  last_data_time: 0.0056   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:16:57 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 1639  total_loss: 0.222  loss_cls: 0.143  loss_box_reg: 0.07105  loss_rpn_cls: 0.0007025  loss_rpn_loc: 0.003494    time: 0.1858  last_time: 0.1823  data_time: 0.0055  last_data_time: 0.0057   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:01 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 1659  total_loss: 0.2305  loss_cls: 0.1574  loss_box_reg: 0.072  loss_rpn_cls: 0.0004082  loss_rpn_loc: 0.002273    time: 0.1857  last_time: 0.1887  data_time: 0.0057  last_data_time: 0.0058   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:04 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 1679  total_loss: 0.2261  loss_cls: 0.1492  loss_box_reg: 0.0698  loss_rpn_cls: 0.002038  loss_rpn_loc: 0.002428    time: 0.1857  last_time: 0.1619  data_time: 0.0062  last_data_time: 0.0061   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:08 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 1699  total_loss: 0.2278  loss_cls: 0.1612  loss_box_reg: 0.06981  loss_rpn_cls: 0.0006603  loss_rpn_loc: 0.002912    time: 0.1857  last_time: 0.1745  data_time: 0.0057  last_data_time: 0.0054   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:12 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 1719  total_loss: 0.1986  loss_cls: 0.109  loss_box_reg: 0.05598  loss_rpn_cls: 0.00194  loss_rpn_loc: 0.003507    time: 0.1857  last_time: 0.1504  data_time: 0.0053  last_data_time: 0.0057   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:15 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 1739  total_loss: 0.2665  loss_cls: 0.1721  loss_box_reg: 0.09003  loss_rpn_cls: 0.0003991  loss_rpn_loc: 0.003468    time: 0.1858  last_time: 0.1822  data_time: 0.0060  last_data_time: 0.0052   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:19 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 1759  total_loss: 0.2847  loss_cls: 0.1916  loss_box_reg: 0.07755  loss_rpn_cls: 0.0003964  loss_rpn_loc: 0.003497    time: 0.1858  last_time: 0.1979  data_time: 0.0051  last_data_time: 0.0072   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:23 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 1779  total_loss: 0.2466  loss_cls: 0.1515  loss_box_reg: 0.05745  loss_rpn_cls: 0.00089  loss_rpn_loc: 0.003647    time: 0.1858  last_time: 0.1604  data_time: 0.0057  last_data_time: 0.0056   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:27 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 1799  total_loss: 0.1843  loss_cls: 0.1296  loss_box_reg: 0.04949  loss_rpn_cls: 0.0005442  loss_rpn_loc: 0.003063    time: 0.1858  last_time: 0.1822  data_time: 0.0051  last_data_time: 0.0057   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:30 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 1819  total_loss: 0.1989  loss_cls: 0.1095  loss_box_reg: 0.06368  loss_rpn_cls: 0.001781  loss_rpn_loc: 0.002832    time: 0.1858  last_time: 0.1585  data_time: 0.0050  last_data_time: 0.0055   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:34 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 1839  total_loss: 0.2165  loss_cls: 0.1219  loss_box_reg: 0.06548  loss_rpn_cls: 0.0002157  loss_rpn_loc: 0.002009    time: 0.1858  last_time: 0.1913  data_time: 0.0053  last_data_time: 0.0053   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:38 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 1859  total_loss: 0.2184  loss_cls: 0.1421  loss_box_reg: 0.06423  loss_rpn_cls: 0.0003097  loss_rpn_loc: 0.002461    time: 0.1858  last_time: 0.2047  data_time: 0.0049  last_data_time: 0.0046   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:42 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 1879  total_loss: 0.2569  loss_cls: 0.1457  loss_box_reg: 0.07828  loss_rpn_cls: 0.001249  loss_rpn_loc: 0.00573    time: 0.1858  last_time: 0.1792  data_time: 0.0050  last_data_time: 0.0047   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:45 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 1899  total_loss: 0.2421  loss_cls: 0.1611  loss_box_reg: 0.06753  loss_rpn_cls: 0.0006517  loss_rpn_loc: 0.005754    time: 0.1858  last_time: 0.1858  data_time: 0.0051  last_data_time: 0.0052   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:49 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 1919  total_loss: 0.2181  loss_cls: 0.1326  loss_box_reg: 0.07246  loss_rpn_cls: 0.000664  loss_rpn_loc: 0.002797    time: 0.1858  last_time: 0.1835  data_time: 0.0051  last_data_time: 0.0046   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:53 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 1939  total_loss: 0.2693  loss_cls: 0.1444  loss_box_reg: 0.0691  loss_rpn_cls: 0.0003853  loss_rpn_loc: 0.002834    time: 0.1857  last_time: 0.1849  data_time: 0.0051  last_data_time: 0.0051   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:17:56 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 1959  total_loss: 0.1908  loss_cls: 0.1096  loss_box_reg: 0.06805  loss_rpn_cls: 0.0007601  loss_rpn_loc: 0.002301    time: 0.1857  last_time: 0.1855  data_time: 0.0051  last_data_time: 0.0053   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:18:00 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 1979  total_loss: 0.2633  loss_cls: 0.1757  loss_box_reg: 0.06553  loss_rpn_cls: 0.0005852  loss_rpn_loc: 0.002437    time: 0.1857  last_time: 0.2033  data_time: 0.0051  last_data_time: 0.0050   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:18:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1999  total_loss: 0.2172  loss_cls: 0.1255  loss_box_reg: 0.06486  loss_rpn_cls: 0.0005049  loss_rpn_loc: 0.002577    time: 0.1857  last_time: 0.2017  data_time: 0.0049  last_data_time: 0.0043   lr: 0.005  max_mem: 1744M\n",
      "\u001b[32m[04/04 20:18:05 d2.engine.hooks]: \u001b[0mOverall training speed: 1998 iterations in 0:06:11 (0.1857 s / it)\n",
      "\u001b[32m[04/04 20:18:05 d2.engine.hooks]: \u001b[0mTotal training time: 0:06:30 (0:00:19 on hooks)\n",
      "394.36487102508545\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "#increase max iter accordingly.\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"train\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.DEVICE = 'cuda' # cuda\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "cfg.SOLVER.WARMUP_ITERS = 500\n",
    "cfg.SOLVER.GAMMA = 0.0005\n",
    "cfg.SOLVER.BASE_LR = 0.005\n",
    "cfg.SOLVER.MAX_ITER = 2000 # (train_size / batch_size) * 100\n",
    "cfg.DATALOADER.AUGMENTATIONS = [(\"CustomMapper\", custom_mapper),]\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256 # 512\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(MetadataCatalog.get(\"train\").thing_classes)\n",
    "cfg.SOLVER.STEPS = (20500, )\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "import time as t\n",
    "s1 = t.time()\n",
    "try:\n",
    "  trainer.train()\n",
    "except:\n",
    "  None\n",
    "s2 = t.time()\n",
    "print(s2-s1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4066836,
     "sourceId": 7149559,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 641.55128,
   "end_time": "2024-04-04T20:18:08.119349",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-04T20:07:26.568069",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
